{
    "name": "root",
    "gauges": {
        "PetFollower.Policy.Entropy.mean": {
            "value": 1.495390772819519,
            "min": 1.4438161849975586,
            "max": 1.495390772819519,
            "count": 3
        },
        "PetFollower.Policy.Entropy.sum": {
            "value": 14910.541015625,
            "min": 14529.1220703125,
            "max": 14910.541015625,
            "count": 3
        },
        "PetFollower.Environment.EpisodeLength.mean": {
            "value": 1021.9166666666666,
            "min": 96.56338028169014,
            "max": 1021.9166666666666,
            "count": 3
        },
        "PetFollower.Environment.EpisodeLength.sum": {
            "value": 12263.0,
            "min": 6856.0,
            "max": 12263.0,
            "count": 3
        },
        "PetFollower.Step.mean": {
            "value": 29964.0,
            "min": 9999.0,
            "max": 29964.0,
            "count": 3
        },
        "PetFollower.Step.sum": {
            "value": 29964.0,
            "min": 9999.0,
            "max": 29964.0,
            "count": 3
        },
        "PetFollower.Policy.ExtrinsicValueEstimate.mean": {
            "value": 20.179306030273438,
            "min": 16.483572006225586,
            "max": 20.179306030273438,
            "count": 3
        },
        "PetFollower.Policy.ExtrinsicValueEstimate.sum": {
            "value": 3289.226806640625,
            "min": 3289.226806640625,
            "max": 3692.880859375,
            "count": 3
        },
        "PetFollower.Environment.CumulativeReward.mean": {
            "value": 228.63333462675413,
            "min": 19.480281714402455,
            "max": 228.63333462675413,
            "count": 3
        },
        "PetFollower.Environment.CumulativeReward.sum": {
            "value": 2743.6000155210495,
            "min": 1383.1000017225742,
            "max": 2743.6000155210495,
            "count": 3
        },
        "PetFollower.Policy.ExtrinsicReward.mean": {
            "value": 228.63333462675413,
            "min": 19.480281714402455,
            "max": 228.63333462675413,
            "count": 3
        },
        "PetFollower.Policy.ExtrinsicReward.sum": {
            "value": 2743.6000155210495,
            "min": 1383.1000017225742,
            "max": 2743.6000155210495,
            "count": 3
        },
        "PetFollower.Losses.PolicyLoss.mean": {
            "value": 0.2444905470087711,
            "min": 0.2444905470087711,
            "max": 0.25188105761755286,
            "count": 3
        },
        "PetFollower.Losses.PolicyLoss.sum": {
            "value": 18.825772119675374,
            "min": 18.825772119675374,
            "max": 19.646722494169122,
            "count": 3
        },
        "PetFollower.Losses.ValueLoss.mean": {
            "value": 8.525167878978685,
            "min": 6.547741575444716,
            "max": 13.881189277834673,
            "count": 3
        },
        "PetFollower.Losses.ValueLoss.sum": {
            "value": 656.4379266813588,
            "min": 510.7238428846878,
            "max": 1082.7327636711045,
            "count": 3
        },
        "PetFollower.Policy.LearningRate.mean": {
            "value": 0.00028499959980532983,
            "min": 0.00028499959980532983,
            "max": 0.00029696706254944103,
            "count": 3
        },
        "PetFollower.Policy.LearningRate.sum": {
            "value": 0.021944969185010398,
            "min": 0.021944969185010398,
            "max": 0.0231634308788564,
            "count": 3
        },
        "PetFollower.Policy.Epsilon.mean": {
            "value": 0.19499986493506496,
            "min": 0.19499986493506496,
            "max": 0.1989890205128205,
            "count": 3
        },
        "PetFollower.Policy.Epsilon.sum": {
            "value": 15.014989600000002,
            "min": 15.014989600000002,
            "max": 15.521143599999998,
            "count": 3
        },
        "PetFollower.Policy.Beta.mean": {
            "value": 0.0005000000000000001,
            "min": 0.0005000000000000001,
            "max": 0.0005000000000000001,
            "count": 3
        },
        "PetFollower.Policy.Beta.sum": {
            "value": 0.038500000000000006,
            "min": 0.038500000000000006,
            "max": 0.03900000000000001,
            "count": 3
        },
        "PetFollower.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        },
        "PetFollower.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1744060878",
        "python_version": "3.10.12 (main, Mar 22 2025, 22:00:24) [Clang 16.0.0 (clang-1600.0.26.6)]",
        "command_line_arguments": "/Users/helenwu/.pyenv/versions/3.10.12/bin/mlagents-learn petfollower_config.yaml --run-id=petfollower4",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.6.0",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1744061085"
    },
    "total": 206.92678208393045,
    "count": 1,
    "self": 0.0029546250589191914,
    "children": {
        "run_training.setup": {
            "total": 0.018775499891489744,
            "count": 1,
            "self": 0.018775499891489744
        },
        "TrainerController.start_learning": {
            "total": 206.90505195898004,
            "count": 1,
            "self": 0.28309949091635644,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.489543458912522,
                    "count": 1,
                    "self": 7.489543458912522
                },
                "TrainerController.advance": {
                    "total": 198.9788420512341,
                    "count": 35394,
                    "self": 0.25063445954583585,
                    "children": {
                        "env_step": {
                            "total": 181.84142334992066,
                            "count": 35394,
                            "self": 172.30998303787783,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 9.341367462649941,
                                    "count": 35394,
                                    "self": 0.6808134815655649,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 8.660553981084377,
                                            "count": 35284,
                                            "self": 8.660553981084377
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.19007284939289093,
                                    "count": 35393,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 138.23492000438273,
                                            "count": 35393,
                                            "is_parallel": true,
                                            "self": 40.173512525623664,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0003684998955577612,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00014925003051757812,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00021924986504018307,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00021924986504018307
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 98.06103897886351,
                                                    "count": 35393,
                                                    "is_parallel": true,
                                                    "self": 0.8189414462540299,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 2.0608184384182096,
                                                            "count": 35393,
                                                            "is_parallel": true,
                                                            "self": 2.0608184384182096
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 92.91565107461065,
                                                            "count": 35393,
                                                            "is_parallel": true,
                                                            "self": 92.91565107461065
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 2.2656280195806175,
                                                            "count": 35393,
                                                            "is_parallel": true,
                                                            "self": 1.0687476361636072,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 1.1968803834170103,
                                                                    "count": 70786,
                                                                    "is_parallel": true,
                                                                    "self": 1.1968803834170103
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 16.8867842417676,
                            "count": 35393,
                            "self": 0.3404661843087524,
                            "children": {
                                "process_trajectory": {
                                    "total": 1.0414383446332067,
                                    "count": 35393,
                                    "self": 1.0414383446332067
                                },
                                "_update_policy": {
                                    "total": 15.504879712825641,
                                    "count": 274,
                                    "self": 2.3843999193049967,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 13.120479793520644,
                                            "count": 9918,
                                            "self": 13.120479793520644
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.15356695791706443,
                    "count": 1,
                    "self": 0.0004986238200217485,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.15306833409704268,
                            "count": 1,
                            "self": 0.15306833409704268
                        }
                    }
                }
            }
        }
    }
}